system:
  log_level: "INFO"  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
  log_directory: "/var/log/llm-security"  
  max_log_size_mb: 50  

llm:
  model_name: "llama3"  # Name of the model to use in ChatOllama (e.g., llama3, gpt3)
  model_url: "http://localhost:11434"  # Base URL for the LLM service (ChatOllama API endpoint)
  temperature: 0.7  # Controls the randomness of the response from the LLM
  max_tokens: 512

vector_database:
  index_path: "/path/to/faiss_index.bin" 
  metadata_path: "/path/to/faiss_metadata.pkl" 
  dimension: 384 

data_collection:
  syslog_path: "/var/log/syslog"
  log_batch_size: 100
  anomaly_detection_threshold: 0.9  # Threshold for anomaly detection in logs (0-1 range)

rag:
  top_k_results: 5  
  retriever_model: "sentence-transformer"